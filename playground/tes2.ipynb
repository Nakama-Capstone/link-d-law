{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/viandwi24/projects/learn/nakama-capstone/playground/tes2.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viandwi24/projects/learn/nakama-capstone/playground/tes2.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/viandwi24/projects/learn/nakama-capstone/playground/tes2.ipynb#W0sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Latih model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/viandwi24/projects/learn/nakama-capstone/playground/tes2.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(padded_sequences, target_pasals, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1102\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1104\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m     )\n\u001b[1;32m   1110\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1111\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1115\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Data latih\n",
    "data = [\n",
    "    (1, 1, \"jadi presiden yah jangan korupsi\"),\n",
    "    (1, 2, \"ya kali presiden korupsi\"),\n",
    "    (2, 3, \"korupsi memding dpr aja\"),\n",
    "    (2, 4, \"prabowo presidenku gibran cawapres ku\"),\n",
    "    (3, 5, \"ya kali anies ngurus banjir aja lah dijakarta\"),\n",
    "]\n",
    "\n",
    "# Pisahkan data ke dalam input dan target\n",
    "input_texts = [entry[2] for entry in data]\n",
    "target_pasals = [entry[1] for entry in data]\n",
    "\n",
    "# Inisialisasi tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(input_texts)\n",
    "\n",
    "# Ubah teks ke dalam urutan angka\n",
    "sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "# Padding urutan agar memiliki panjang yang sama\n",
    "padded_sequences = pad_sequences(sequences)\n",
    "\n",
    "# Bangun model sederhana\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=padded_sequences.shape[1]),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Latih model\n",
    "model.fit(padded_sequences, target_pasals, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 10ms/step\n",
      "[1 2 3 4 5 1 2 3 4 5]\n",
      "jadi presiden yah jangan korupsi\n",
      "ya kali presiden korupsi\n",
      "korupsi memding dpr aja\n",
      "prabowo presidenku gibran cawapres ku\n",
      "ya kali anies ngurus banjir aja lah dijakarta\n",
      "jadi presiden yah jangan korupsi\n",
      "ya kali presiden korupsi\n",
      "korupsi memding dpr aja\n",
      "prabowo presidenku gibran cawapres ku\n",
      "ya kali anies ngurus banjir aja lah dijakarta\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Output pasals: [None]\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk memprediksi pasal\n",
    "def predict_pasal(input_text):\n",
    "    # Ubah input pengguna ke dalam urutan angka\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_input = pad_sequences(input_sequence, maxlen=padded_sequences.shape[1])\n",
    "    \n",
    "    # Prediksi nomor pasal\n",
    "    predicted_pasals = model.predict(padded_input)\n",
    "    predicted_pasals = [round(p[0]) for p in predicted_pasals]  # Bulatkan hasil prediksi\n",
    "    \n",
    "    return predicted_pasals\n",
    "\n",
    "# Fungsi untuk mendapatkan teks pasal\n",
    "def get_pasal_text(pasal_number):\n",
    "    for entry in data:\n",
    "        if entry[1] == pasal_number:\n",
    "            return entry[2]\n",
    "    return None\n",
    "\n",
    "# Contoh penggunaan\n",
    "input_text = \"presiden korupsi\"\n",
    "predicted_pasals = predict_pasal(input_text)\n",
    "\n",
    "for pasal_number in predicted_pasals:\n",
    "    pasal_text = get_pasal_text(pasal_number)\n",
    "    if pasal_text:\n",
    "        print(f\"Pasal {pasal_number}: {pasal_text}\")\n",
    "    else:\n",
    "        print(f\"Tidak dapat menemukan teks untuk Pasal {pasal_number}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
